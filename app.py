import streamlit as st
from openai import OpenAI
import sys

with st.sidebar:
    st.markdown(f"""
 <center>
<img src='http://tuchuang.jojo-shuang.top/temp/119046852_p0.png'width='100'/>
<h1> MoBot <sup>beta</sup><h1/>
</center>""",unsafe_allow_html=True)
    system_message=st.text_area("è§’è‰²å®šä¹‰","ä½ æ˜¯ä¸€ä¸ªèƒ½å¸®åŠ©ç”¨æˆ·çš„aiåŠ©æ‰‹")
    temperature=st.slider("åˆ›é€ åŠ›è°ƒèŠ‚",min_value=0.0,max_value=2.0,step=0.1)
st.title("ğŸ¤–AièŠå¤©æœºå™¨äºº")
# åˆå§‹åŒ–ç•Œé¢çš„èŠå¤©æ¡†
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "HI I am MoBot å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"
    }, {
        "role": "user",
        "content": "ä½ å¥½"
    }]

# å±•ç¤ºå†å²èŠå¤©è®°å½•
for message in st.session_state.messages:
    # å¢åŠ å¯¹ 'content' é”®å­˜åœ¨æ€§çš„æ£€æŸ¥
    if "content" in message:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    else:
        # å¦‚æœ 'content' ä¸å­˜åœ¨ï¼Œå¯ä»¥é€‚å½“å¤„ç†ï¼Œæ¯”å¦‚æ‰“å°è­¦å‘Šæˆ–è·³è¿‡è¿™æ¡æ¶ˆæ¯
        st.warning(f"Warning: Message missing 'content': {message}")

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(api_key="sk-be9be9b062f340d2b20bea38375e4173", base_url="https://api.deepseek.com")

# åˆå§‹åŒ–æ¶ˆæ¯å†å²
if "messageHistory" not in st.session_state:
    st.session_state.messageHistory = []


def chat_stream(query, system_message = None, temperature = 1):
    if system_message:
        st.session_state.messageHistory.append({"role": "system", "content": system_message})
    st.session_state.messageHistory.append({"role": "user", "content": query})
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=st.session_state.messageHistory,
        stream=True
    )
    return response


# ç”¨æˆ·è¾“å…¥
user_query = st.chat_input("è¯´ç‚¹ä»€ä¹ˆ...")
if user_query:
    with st.chat_message("user"):
        st.write(user_query)
    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("assistant"):
        with st.spinner(""):
            response = chat_stream(user_query, system_message, temperature)
            message_placeholder = st.empty()
            ai_response = ""
            for chunk in response:
                if chunk.choices and hasattr(chunk.choices[0].delta, "content"):
                    ai_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(ai_response)
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
